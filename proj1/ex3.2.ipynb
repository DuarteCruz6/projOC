{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9904a3d",
   "metadata": {},
   "source": [
    "## 3.2 Profiling and Optimizing Data Cache Accesses\n",
    "## 3.2.1 Straightforward implementation\n",
    "\n",
    "### a) What is the total amount of memory that is required to accommodate each of these matrices?\n",
    "\n",
    "### b) Fill the following table with the obtained data.\n",
    "| Info                                                | Data               |\n",
    "| :-------------------------------------------------- |:------------------ |\n",
    "| Total number of L1 data cache misses                |               x10^6|             \n",
    "| Total number of load / store instructions completed |               x10^6|\n",
    "| Total number of clock cycles                        |               x10^6|\n",
    "| Elapsed time                                        |             seconds|\n",
    "\n",
    "### c) Evaluate the resulting L1 data cache Hit-Rate:\n",
    "\n",
    "## 3.2.2 First Optimization: Matrix transpose before multiplication [2]\n",
    "\n",
    "### a) Fill the following table with the obtained data.\n",
    "\n",
    "| Info                                                | Data               |\n",
    "| :-------------------------------------------------- |:------------------ |\n",
    "| Total number of L1 data cache misses                |               x10^6|             \n",
    "| Total number of load / store instructions completed |               x10^6|\n",
    "| Total number of clock cycles                        |               x10^6|\n",
    "| Elapsed time                                        |             seconds|\n",
    "\n",
    "### b) Evaluate the resulting L1 data cache Hit-Rate:\n",
    "\n",
    "### c) Fill the following table with the obtained data.\n",
    "\n",
    "| Info                                                | Data               |\n",
    "| :-------------------------------------------------- |:------------------ |\n",
    "| Total number of L1 data cache misses                |               x10^6|             \n",
    "| Total number of load / store instructions completed |               x10^6|\n",
    "| Total number of clock cycles                        |               x10^6|\n",
    "| Elapsed time                                        |             seconds|\n",
    "\n",
    "#### Comment on the obtained results when including the matrix transposition in the execution time:\n",
    "\n",
    "### d) Compare the obtained results with those that were obtained for the straightforward implementation, by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedups.\n",
    "\n",
    "∆HitRate = HitRate mm2 − HitRate mm1:\n",
    "\n",
    "Speedup(#Clocks) = #Clocks mm1/#Clocks mm2:\n",
    "\n",
    "Speedup(Time) = Time mm1/Time mm2:\n",
    "\n",
    "Comment: \n",
    "\n",
    "## 3.2.3 Second Optimization: Blocked (tiled) matrix multiply [2]\n",
    "\n",
    "### a) How many matrix elements can be accommodated in each cache line?\n",
    "\n",
    "### b) Fill the following table with the obtained data.\n",
    "\n",
    "| Info                                                | Data               |\n",
    "| :-------------------------------------------------- |:------------------ |\n",
    "| Total number of L1 data cache misses                |               x10^6|             \n",
    "| Total number of load / store instructions completed |               x10^6|\n",
    "| Total number of clock cycles                        |               x10^6|\n",
    "| Elapsed time                                        |             seconds|\n",
    "\n",
    "### c) Evaluate the resulting L1 data cache Hit-Rate:\n",
    "\n",
    "### d) Compare the obtained results with those that were obtained for the straightforward implementation, by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedup.\n",
    "\n",
    "∆HitRate = HitRatemm3 − HitRatemm1:\n",
    "\n",
    "Speedup(#Clocks) = #Clocksmm1/#Clocksmm3:\n",
    "\n",
    "Comment:\n",
    "\n",
    "### e) Compare the obtained results with those that were obtained for the matrix transpose implementation by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedup. If the obtained speedup is positive, but the difference of the resulting hit-rates is negative, how do you explain the performance improvement? (Hint: study the hit-rates of the L2 cache for both implementations;)\n",
    "\n",
    "∆HitRate = HitRatemm3 − HitRatemm2:\n",
    "\n",
    "Speedup(#Clocks) = #Clocksmm2/#Clocksmm3:\n",
    "\n",
    "Comment:\n",
    "\n",
    "## 3.2.3 Comparing results against the CPU specifications\n",
    "\n",
    "### Now that you have characterized the cache on your lab computer, you are going to compare it against the manufacturer’s specification. For this you can check the device’s datasheet, or make use of the command lscpu. Comment on the results.\n",
    "\n",
    "Caches (sum of all):         \n",
    "  L1d:                       192 KiB (6 instances)\n",
    "  L1i:                       192 KiB (6 instances)\n",
    "  L2:                        1.5 MiB (6 instances)\n",
    "  L3:                        9 MiB (1 instance)\n",
    "\n",
    "The device has:\n",
    "- 6 cores of 32 KiB L1 Data (L1d) cache\n",
    "\n",
    "- 6 cores of 32 KiB L1 Instruction (L1i) cache\n",
    "\n",
    "- 6 cores of 256 KiB L2 cache\n",
    "\n",
    "- 1 core of 9 MiB L3 cache that is shared among all 6 cores "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
